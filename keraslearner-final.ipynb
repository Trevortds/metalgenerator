{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing stuff\n",
    "\n",
    "Changes: adding word tokenize, making the \"chars\" vector contain words rather than actual chars. Yes, this is confusing, but hopefully if I say it right up front it won't be so bad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import cmudict\n",
    "import sys\n",
    "import re\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "characterlstm = True\n",
    "\n",
    "pronouncing_dict = cmudict.dict()\n",
    "def nsyl(word):\n",
    "    if word not in pronouncing_dict:\n",
    "        if re.search('\\W', word):\n",
    "            # if the word has non-word characters\n",
    "            return 0\n",
    "        else:\n",
    "            # take a guess: number of vowels\n",
    "            return len(re.findall(\"[aeiou]\", x))\n",
    "    return [len(list(y for y in x if y[-1].isdigit())) for x in pronouncing_dict[word.lower()]][0]\n",
    "\n",
    "\n",
    "# I'm making this from Trung Tran's LSTM tutorial. \n",
    "# I'm going to try to annotate it in my own words so that I can understand what's happening\n",
    "# And then change it to do what I want. \n",
    "\n",
    "data = []\n",
    "avgsyllables = 0\n",
    "linecount = 0\n",
    "\n",
    "with open(\"lyricsfixed.txt\", 'r') as f:\n",
    "    if characterlstm:\n",
    "        for line in f:\n",
    "            data += list(line)\n",
    "\n",
    "    else:\n",
    "        for line in f:\n",
    "            \n",
    "            for word in word_tokenize(line):\n",
    "                data.append(word.lower())\n",
    "                avgsyllables += nsyl(word)\n",
    "            linecount += 1\n",
    "            data.append(\"\\n\") # I want the machine to learn newlines\n",
    "            # since they're part of the lyrics\n",
    "            # and have similar meaning to words. \n",
    "\n",
    "        avgsyllables = avgsyllables / linecount\n",
    "\n",
    "data = data[:1000]        \n",
    "\n",
    "# features. This will eventually be words\n",
    "# also, this line is what killed my results. I trained a model for a full day\n",
    "# it was performing great. \n",
    "chars = sorted(list(set(data)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data\n",
    "\n",
    "Only change here is the len_sequence. I made it 700 words, it'll be learning from multiple songs at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# conversion to numbers. This is actually a really clever solution\n",
    "ix_to_char = {ix:char for ix, char in enumerate(chars)}\n",
    "char_to_ix = {char:ix for ix, char in enumerate(chars)}\n",
    "\n",
    "# setting up parameters. \n",
    "num_features = len(chars)\n",
    "# length of the group of words that the lstm will be shown at a time\n",
    "len_sequence = 70\n",
    "num_sequences = len(data)//len_sequence\n",
    "\n",
    "\n",
    "# need input and output tapes for the LSTM\n",
    "X = np.zeros((len(data)//len_sequence, len_sequence, num_features))\n",
    "y = np.zeros((len(data)//len_sequence, len_sequence, num_features))\n",
    "\n",
    "# for each of the sequences\n",
    "for i in range(0, len(data)//len_sequence):\n",
    "    # select the characters in the data that correspond to this sequence\n",
    "    X_sequence = data[i*len_sequence:(i+1)*len_sequence]\n",
    "    # convert to numeric\n",
    "    X_sequence_ix = [char_to_ix[value] for value in X_sequence]\n",
    "    #initialize \n",
    "    input_sequence = np.zeros((len_sequence, num_features))\n",
    "    for j in range(len_sequence):\n",
    "        #make a 1-hot vector for each of the letters the lstm is being shown\n",
    "        input_sequence[j][X_sequence_ix[j]] = 1\n",
    "\n",
    "    X[i] = input_sequence\n",
    "    \n",
    "    # select targets: the symbol that follows\n",
    "    y_sequence = data[i*len_sequence+1:(i+1)*len_sequence+1]\n",
    "    # convert to numeric\n",
    "    y_sequence_ix = [char_to_ix[value] for value in y_sequence]\n",
    "    target_sequence = np.zeros((len_sequence, num_features))\n",
    "    for j in range(len_sequence):\n",
    "        target_sequence[j][y_sequence_ix[j]] = 1\n",
    "        \n",
    "    y[i] = target_sequence\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up network\n",
    "\n",
    "Taking cues from Tran, I set it up to have 700 hidden states, with 0.3 dropout at the first layer and three layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize a sequential network\n",
    "model = Sequential()\n",
    "\n",
    "hidden_dim = 700\n",
    "layer_num = 3\n",
    "\n",
    "# add an initial lstm layer\n",
    "# I don't know why the input shape needs to be a tuple\n",
    "# the return-sequences parameter makes it give you multiple outputs\n",
    "model.add(LSTM(hidden_dim, \n",
    "               input_shape=(None, num_features), \n",
    "               return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# add more layers\n",
    "# I don't really know what adding a layer to an LSTM means, \n",
    "#  they're only ever shown with one.\n",
    "\n",
    "for i in range(layer_num-1):\n",
    "    model.add(LSTM(hidden_dim, return_sequences=True))\n",
    "\n",
    "# I don't see why the dense layer is necessary, but Tran says it is.\n",
    "# and in order to get the dense layer to work, a time distributed layer\n",
    "#  needs to go between.\n",
    "\n",
    "model.add(TimeDistributed(Dense(num_features)))\n",
    "\n",
    "# pick an activation for this layer\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# pick a loss function and optimization method. \n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic\n",
    "\n",
    "This is the part where I get to be creative. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_pick(model_predictions):\n",
    "    # Select random character from the best ten\n",
    "    candidates = np.argpartition(model_predictions[0,-1], -10)[-10:]\n",
    "    return [np.random.choice(candidates)]\n",
    "    \n",
    "\n",
    "def softmax_pick(model_predictions, top_ten = False):\n",
    "    candidates = np.argpartition(model_predictions[0,-1], -10)[-10:]\n",
    "    probs = [model_predictions[0,-1, i] for i in candidates]\n",
    "    probs = softmax(np.asarray(probs), 0.4)\n",
    "    print(candidates)\n",
    "    print(probs)\n",
    "    if top_ten:\n",
    "        return [np.random.choice(candidates, p=probs)]\n",
    "    else:\n",
    "        return [np.random.choice(model_predictions.shape[2], p=model_predictions[0,-1])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def beam_search(model_predictions, history, i):\n",
    "    # Select the character most likely to lead down a good path\n",
    "    best_ix = 0\n",
    "    candidates = np.argpartition(model_predictions[0,-1], -10)[-10:]\n",
    "#     print(model_predictions.shape) (1, 1, numfeatures)\n",
    "    print(np.argmax(model_predictions[0], 1))\n",
    "    print(candidates)\n",
    "    candidate_predictions = [model_predictions[0, -1, c] for c in candidates]\n",
    "    print(candidate_predictions)\n",
    "#     print(normalize(np.asarray([candidate_predictions])))\n",
    "    \n",
    "    h = np.zeros(len(candidates))\n",
    "    \n",
    "    for i in range(len(candidates)):\n",
    "        candidate = candidates[i]\n",
    "        pred = candidate_predictions[i]\n",
    "        word = ix_to_char[candidate]\n",
    "        print(\"candidate: {} score: {} word:{}\".format(candidate, model_predictions[0,0,candidate], word))\n",
    "\n",
    "        h[i] = heuristic(history, word, pred)\n",
    "        print(\"adjucted score: \", h[i])\n",
    "#         if score < best_score:\n",
    "#             best_score = score\n",
    "#             best_candidate = candidate\n",
    "    print(\"scores: \", h)\n",
    "    # softmax preserves ranking but squishes values\n",
    "    # temperature lets you play with how far the values change\n",
    "    # if > 1 rank 1 is further from rank 2\n",
    "    # if < 1 rank 1 is closer to rank 2\n",
    "    h = softmax(h, 0.4) # 0 is \n",
    "    print(\"softmax scores: \", h)\n",
    "    return [np.random.choice(candidates, p=h)]\n",
    "    \n",
    "#     return [best_candidate]\n",
    "#     return np.argmax(model_predictions[0], 1)\n",
    "\n",
    "def heuristic(history, word, prediction):\n",
    "    # don't give more than two newlines in a row. \n",
    "    # maximizing heuristic\n",
    "    if word == '\\n' and len(history) > 1 and history[-2] == '\\n':\n",
    "        return 1000\n",
    "    \n",
    "    line = []\n",
    "    syl_count = 0\n",
    "    for back_word in history[::-1]:\n",
    "        if back_word == '\\n':\n",
    "            break\n",
    "        else:\n",
    "            syl_count = nsyl(back_word)\n",
    "            line.insert(0, back_word)\n",
    "    syl_count += nsyl(word)\n",
    "    print(\"syllable count \", syl_count)\n",
    "    # return square difference between number \n",
    "    # of syllables in the sentence and the average\n",
    "    # this may cause a preference for long words at the beginning\n",
    "    # we'll see. \n",
    "    \n",
    "    return prediction * (syl_count - avgsyllables)**-2\n",
    "    \n",
    "\n",
    "# copied from http://stackoverflow.com/questions/41902047/how-to-calculate-robust-softmax-function-with-temperature?noredirect=1&lq=1\n",
    "def softmax(x, tau):\n",
    "    \"\"\" Returns softmax probabilities with temperature tau\n",
    "        Input:  x -- 1-dimensional array\n",
    "        Output: s -- 1-dimensional array\n",
    "    \"\"\"\n",
    "    e_x = np.exp(x / tau)\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "14/14 [==============================] - 4s - loss: 3.1322\n",
      "h[29 31  0 34 28 26 24  1 16 20]\n",
      "[ 0.0999421   0.09994443  0.09996352  0.09999608  0.10008285  0.10000158\n",
      "  0.09997183  0.10005748  0.09998505  0.10005513]\n",
      "C[29 26 31 22 24 34 28  1 16 20]\n",
      "[ 0.09976836  0.09985027  0.09986342  0.09989078  0.09992778  0.10000883\n",
      "  0.100361    0.1002129   0.09993277  0.10018394]\n",
      "w[29 26 28 34 31 22  1 24 16 20]\n",
      "[ 0.09928612  0.09936997  0.10117826  0.10008316  0.09963581  0.09984611\n",
      "  0.10060626  0.09981296  0.09974586  0.1004355 ]\n",
      ",[29 23 31 34 24 22  1 28 16 20]\n",
      "[ 0.09787003  0.09796874  0.09901032  0.10011172  0.09948039  0.09967142\n",
      "  0.10180697  0.10382766  0.09918876  0.10106396]\n",
      "i[33 31 24 34 22 23  1 28 16 20]\n",
      "[ 0.09470982  0.09824666  0.09837499  0.09859708  0.09871584  0.09524909\n",
      "  0.10495213  0.11046143  0.09796952  0.10272345]\n",
      "l[34 23 33 28 31 22  1 24 16 20]\n",
      "[ 0.09339805  0.09366452  0.0937342   0.11163446  0.10045861  0.09530064\n",
      "  0.10924482  0.09785537  0.09755271  0.10715654]\n",
      " [23 32 33 29 24 28  1 31 16 20]\n",
      "[ 0.09333383  0.09457076  0.09452514  0.09665088  0.0972324   0.10260969\n",
      "  0.11122209  0.10027871  0.09829745  0.111279  ]\n",
      "u[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09301634  0.09447137  0.09440996  0.09468193  0.09924489  0.09866782\n",
      "  0.09848579  0.10196729  0.11133613  0.11371853]\n",
      "o[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09338     0.09439764  0.09389684  0.09485537  0.09874911  0.09827101\n",
      "  0.09817886  0.10301934  0.11061189  0.11463989]\n",
      "h[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09360365  0.09440304  0.09381612  0.09485134  0.09855231  0.09819248\n",
      "  0.09805637  0.10306107  0.11051515  0.1149485 ]\n",
      "n[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09371625  0.0944109   0.09383998  0.09491751  0.09849159  0.09817872\n",
      "  0.09799172  0.10299592  0.11061934  0.11483809]\n",
      "y[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09377822  0.09440809  0.0938703   0.09496246  0.09845929  0.09818045\n",
      "  0.09798229  0.1029192   0.11074605  0.1146937 ]\n",
      " [26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09381651  0.09441123  0.09388889  0.09498508  0.09845383  0.09819368\n",
      "  0.09798496  0.10286211  0.11081817  0.11458555]\n",
      "\n",
      "[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09384233  0.09441454  0.09390426  0.09499769  0.0984564   0.09820777\n",
      "  0.09799109  0.10281884  0.1108649   0.11450204]\n",
      "f[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09386034  0.09441652  0.09391624  0.09500547  0.09845975  0.09821764\n",
      "  0.09799496  0.10278731  0.11089972  0.11444215]\n",
      "w[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.093872    0.09441771  0.09392449  0.09500992  0.09846264  0.09822502\n",
      "  0.09799802  0.10276639  0.11092424  0.11439958]\n",
      " [26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09387983  0.0944192   0.0939308   0.09501307  0.09846543  0.09823028\n",
      "  0.09799999  0.10275008  0.11093991  0.11437145]\n",
      "u[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09388506  0.09441958  0.09393588  0.09501539  0.09846736  0.09823355\n",
      "  0.09800033  0.10273828  0.11095319  0.11435135]\n",
      "a[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09388876  0.09442079  0.09393913  0.09501687  0.0984689   0.09823604\n",
      "  0.09800068  0.10273045  0.11096041  0.11433795]\n",
      "o[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.0938915   0.0944205   0.09394109  0.09501748  0.09846896  0.09823722\n",
      "  0.09800115  0.10272692  0.11096789  0.11432729]\n",
      "w[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09389291  0.09442096  0.09394265  0.09501831  0.09846997  0.09823847\n",
      "  0.09800109  0.1027234   0.11097114  0.11432106]\n",
      "d[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09389412  0.0944215   0.09394417  0.09501902  0.09847078  0.09823902\n",
      "  0.09800088  0.10272018  0.11097351  0.1143168 ]\n",
      "e[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.0938948   0.09442175  0.09394535  0.09501929  0.09847157  0.09823995\n",
      "  0.09800043  0.10271789  0.11097537  0.11431359]\n",
      "a[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.0938951   0.0944223   0.09394615  0.0950202   0.09847241  0.09823963\n",
      "  0.0979995   0.10271607  0.11097606  0.11431264]\n",
      "y[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09389552  0.09442214  0.09394649  0.09501999  0.09847292  0.09823953\n",
      "  0.0979993   0.10271669  0.11097717  0.11431025]\n",
      "Â€[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09389565  0.09442235  0.09394695  0.09502055  0.09847327  0.09823962\n",
      "  0.09799887  0.10271532  0.11097785  0.11430953]\n",
      "s[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09389579  0.09442206  0.09394736  0.09502073  0.09847324  0.09823904\n",
      "  0.09799822  0.10271543  0.11097914  0.11430907]\n",
      "r[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09389569  0.09442215  0.09394713  0.09502041  0.09847436  0.09823989\n",
      "  0.09799849  0.1027152   0.11097836  0.11430825]\n",
      "v[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09389575  0.09442232  0.09394707  0.0950205   0.09847388  0.09823963\n",
      "  0.09799828  0.10271533  0.1109785   0.11430866]\n",
      " [26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09389575  0.09442306  0.09394731  0.09502105  0.09847397  0.09823969\n",
      "  0.0979982   0.10271438  0.11097841  0.11430818]\n",
      "i[29 31  0 34 28 26 24  1 16 20]\n",
      "[ 0.09994348  0.09995092  0.09995718  0.10001274  0.10008434  0.09998455\n",
      "  0.09996394  0.10006269  0.0999811   0.10005907]\n",
      "a[29 26 31 34 28 24 22  1 16 20]\n",
      "[ 0.09974636  0.09980752  0.0998442   0.1000614   0.10041878  0.09993007\n",
      "  0.09984641  0.10024901  0.09989952  0.10019668]\n",
      "r[29 26 28 34 31 22  1 24 16 20]\n",
      "[ 0.0990921   0.09916716  0.10157701  0.10017095  0.09950009  0.09973513\n",
      "  0.10079458  0.09980358  0.09963248  0.10052684]\n",
      "u[29 23 31 34 24 22  1 28 16 20]\n",
      "[ 0.09706025  0.09714928  0.09862527  0.10002889  0.09931241  0.09933382\n",
      "  0.10253095  0.10566135  0.09887312  0.10142468]\n",
      " [33 31 28 34 23 22  1 24 16 20]\n",
      "[ 0.09410723  0.09870736  0.11264371  0.09686866  0.09421937  0.09737501\n",
      "  0.1062941   0.09796334  0.09768503  0.10413614]\n",
      "g[23 32 29 33 28 31  1 24 16 20]\n",
      "[ 0.09343635  0.09364013  0.09371762  0.09433444  0.10734469  0.10098456\n",
      "  0.10987849  0.09854674  0.09817558  0.10994139]\n",
      "a[26 32 33 28 24 31 16 29  1 20]\n",
      "[ 0.09284265  0.09464739  0.0946693   0.10008749  0.09553361  0.09932373\n",
      "  0.09861637  0.10041586  0.11176925  0.11209429]\n",
      "t[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09329189  0.09439791  0.09403348  0.09484211  0.09897824  0.09836839\n",
      "  0.09831703  0.10275453  0.11069332  0.11432309]\n",
      "i[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09355286  0.09439408  0.09383041  0.09485031  0.09866249  0.09821027\n",
      "  0.09812678  0.10305893  0.11040706  0.1149068 ]\n",
      "s[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09369259  0.09440552  0.09383261  0.09492049  0.09856461  0.09817651\n",
      "  0.09803002  0.10301923  0.11048643  0.11487193]\n",
      " [26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09377354  0.09440643  0.09386244  0.09497915  0.0985171   0.09817724\n",
      "  0.09801719  0.10294238  0.11062482  0.11469974]\n",
      "o[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09382293  0.09441187  0.09388452  0.09500967  0.09850566  0.09819129\n",
      "  0.09801806  0.10287423  0.11071524  0.11456654]\n",
      "o[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09385608  0.09441711  0.09390207  0.09502609  0.09850809  0.098208\n",
      "  0.09802531  0.1028206   0.11077262  0.11446411]\n",
      "s[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09387843  0.09442084  0.0939166   0.09503585  0.09851275  0.09822044\n",
      "  0.0980309   0.1027806   0.11081311  0.11439055]\n",
      "l[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.0938936   0.09442382  0.09392664  0.09504138  0.09851651  0.09823038\n",
      "  0.09803575  0.10275148  0.11084291  0.11433746]\n",
      "e[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09390391  0.0944258   0.09393417  0.09504468  0.09851909  0.09823721\n",
      "  0.09803867  0.10273178  0.11086398  0.11430069]\n",
      " [26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09391056  0.09442721  0.09393919  0.09504718  0.09852126  0.09824087\n",
      "  0.09804048  0.1027187   0.11087792  0.11427671]\n",
      "e[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09391548  0.09442823  0.09394345  0.09504856  0.0985226   0.09824435\n",
      "  0.09804122  0.10270824  0.11088946  0.11425836]\n",
      "n[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09391817  0.0944285   0.09394604  0.0950498   0.09852459  0.09824511\n",
      "  0.0980411   0.10270234  0.11089634  0.11424807]\n",
      "o[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09392092  0.09442923  0.0939479   0.09505062  0.09852415  0.09824685\n",
      "  0.09804142  0.1026981   0.11090266  0.1142382 ]\n",
      "i[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09392209  0.09442952  0.09394943  0.09505118  0.09852488  0.09824757\n",
      "  0.09804112  0.10269422  0.11090594  0.11423402]\n",
      "r[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09392296  0.0944299   0.09395055  0.09505142  0.09852684  0.0982486\n",
      "  0.09804101  0.10269249  0.11090708  0.11422914]\n",
      "n[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.0939234   0.09443034  0.09395133  0.095052    0.09852718  0.09824808\n",
      "  0.09804017  0.10269064  0.11090899  0.11422783]\n",
      "r[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09392407  0.0944306   0.09395187  0.0950521   0.09852761  0.098249\n",
      "  0.09804009  0.10268984  0.11091013  0.11422466]\n",
      "e[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09392458  0.0944313   0.09395253  0.09505241  0.09852715  0.09824947\n",
      "  0.09803985  0.10268793  0.11091144  0.11422337]\n",
      " [26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09392448  0.09443158  0.09395251  0.09505281  0.09852743  0.09824876\n",
      "  0.09803962  0.10268803  0.11091127  0.1142235 ]\n",
      "r[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09392463  0.09443122  0.09395293  0.09505267  0.09852847  0.09824905\n",
      "  0.09803911  0.10268797  0.11091213  0.11422183]\n",
      "r[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.0939247   0.09443133  0.09395307  0.09505275  0.09852885  0.09824917\n",
      "  0.0980388   0.10268767  0.11091217  0.11422147]\n",
      "a[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09392482  0.09443232  0.09395362  0.09505355  0.0985285   0.09824896\n",
      "  0.09803808  0.10268593  0.11091245  0.11422177]\n",
      "o[26 32 24 33 28 31 16 29  1 20]\n",
      "[ 0.09392515  0.09443171  0.09395333  0.09505317  0.09852765  0.09824857\n",
      "  0.09803836  0.10268747  0.11091453  0.11422004]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'iaru gatis oosle enoirnre rrao '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 40\n",
    "model.fit(X, y, batch_size=batch_size, verbose=1, nb_epoch=1)\n",
    "generate_text(model, 30, top_ten = False)\n",
    "generate_text(model, 30, top_ten = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# begin with some random characters and predict the next n characters\n",
    "\n",
    "def generate_text(model, length, top_ten = False):\n",
    "    # generate a number and associated character\n",
    "    ix = [np.random.randint(num_features)]\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    # annoyingly, the big matrix of character sequences is called X\n",
    "    X = np.zeros((1, length, num_features))\n",
    "    joinchar = '' if characterlstm else ''\n",
    "    \n",
    "    for i in range(length):\n",
    "        # for n characters\n",
    "        # update the big matrix with the last prediction\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        # print the last prediction to the command line\n",
    "        print(ix_to_char[ix[-1]], end=joinchar)\n",
    "        # get a new prediction\n",
    "        # instead of taking the max, run beam search \n",
    "        if characterlstm:\n",
    "            ix = softmax_pick(model.predict(X[:, :i+1, :]), top_ten)\n",
    "        else:\n",
    "            ix = beam_search(model.predict(X[:, :i+1, :]), y_char, i)\n",
    "        \n",
    "        # convert to character and append to array\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    \n",
    "\n",
    "    return (joinchar).join(y_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      "265/265 [==============================] - 91s - loss: 5.5687     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "whispers "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'selct_best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1bfb603c3ae9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# every epoch, show some text examples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# this is a function defined below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnb_epoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-85cd4702326f>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(model, length)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# I don't understand why the prediction needs to be subscripted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# I guess the 1 means that you only get one output from argmax?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselct_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# convert to character and append to array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'selct_best' is not defined"
     ]
    }
   ],
   "source": [
    "# I don't know if nb is supposed to mean something. This is just a counter\n",
    "\n",
    "\n",
    "if len(sys.argv) > 1:\n",
    "    model.load_weights(sys.argv[1])\n",
    "    print(re.findall(r'epoch(\\d)', sys.argv[1]))\n",
    "    nb_epoch = int(re.findall(r'epoch(\\d+)', sys.argv[1])[0])\n",
    "    print(\"Using weights in {}\".format(sys.argv[1]))\n",
    "    print(\"epoch: {}\".format(nb_epoch)) \n",
    "else:\n",
    "    print(\"Using a new model\")\n",
    "    nb_epoch = 0\n",
    "batch_size = 40\n",
    "generate_length = 500\n",
    "epoch_per_gen = 1\n",
    "\n",
    "while True:\n",
    "    print(\"\\n\\n\")\n",
    "    # fit the model for one epoch\n",
    "    model.fit(X, y, batch_size=batch_size, verbose=1, nb_epoch=1)\n",
    "    # increment counter\n",
    "    nb_epoch += 1\n",
    "    # every epoch, show some text examples.\n",
    "    # this is a function defined below.\n",
    "    generate_text(model, generate_length)\n",
    "    \n",
    "    if nb_epoch % 10 == 0:\n",
    "        # save every tenth epoch group\n",
    "        print(\"epoch # {}\".format(nb_epoch))\n",
    "        generate_text(model, generate_length)\n",
    "        model.save_weights('checkpoints/checkpoint_{}_epoch{}.hdf5'.format(hidden_dim, nb_epoch))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
